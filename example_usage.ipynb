{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "## Initialize a GeslaDataset object\n",
    "Place the `gesla.py` file in your working directory (or elsewhere on your path), and import the `GeslaDataset` class. Selecting and loading data files requires paths to the metadata .csv file and the directory containing the data files. Initialize a `GeslaDataset` object with these paths as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gesla import GeslaDataset\n",
    "\n",
    "meta_file = \"../GESLAv3/GESLA3_ALL.csv\"\n",
    "data_path = \"../GESLAv3/GESLA3/\"\n",
    "\n",
    "g3 = GeslaDataset(meta_file=meta_file, data_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a single file\n",
    "If you want to work with data from a single record, and you know the filename you want, use the function `file_to_pandas` as follows. The function returns a `pandas.DataFrame` with data and flags, and a `pandas.Series` containing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sea_level</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>use_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-08-19 21:00:00</th>\n",
       "      <td>1.064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-19 22:00:00</th>\n",
       "      <td>0.905</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-19 23:00:00</th>\n",
       "      <td>0.871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-20 00:00:00</th>\n",
       "      <td>0.998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-20 01:00:00</th>\n",
       "      <td>1.198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 19:00:00</th>\n",
       "      <td>1.563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 20:00:00</th>\n",
       "      <td>1.246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:00:00</th>\n",
       "      <td>1.001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00</th>\n",
       "      <td>0.928</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00</th>\n",
       "      <td>1.007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73347 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sea_level  qc_flag  use_flag\n",
       "date_time                                        \n",
       "2010-08-19 21:00:00      1.064        1         1\n",
       "2010-08-19 22:00:00      0.905        1         1\n",
       "2010-08-19 23:00:00      0.871        1         1\n",
       "2010-08-20 00:00:00      0.998        1         1\n",
       "2010-08-20 01:00:00      1.198        1         1\n",
       "...                        ...      ...       ...\n",
       "2018-12-31 19:00:00      1.563        1         1\n",
       "2018-12-31 20:00:00      1.246        1         1\n",
       "2018-12-31 21:00:00      1.001        1         1\n",
       "2018-12-31 22:00:00      0.928        1         1\n",
       "2018-12-31 23:00:00      1.007        1         1\n",
       "\n",
       "[73347 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"acajutla-082c-slv-uhslc\"\n",
    "data, meta = g3.file_to_pandas(filename)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a list of files\n",
    "If you want to work with data from multiple files, and you know the filenames you want, use the function `files_to_xarray` as follows. The function returns a `xarray.Dataset` object containing data, flags, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                  (station: 4, date_time: 289251)\n",
      "Coordinates:\n",
      "  * station                  (station) int64 0 1 2 3\n",
      "  * date_time                (date_time) datetime64[ns] 1971-06-09T05:00:00 ....\n",
      "Data variables: (12/27)\n",
      "    sea_level                (station, date_time) float64 2.29 1.79 ... nan nan\n",
      "    qc_flag                  (station, date_time) float64 1.0 1.0 ... nan nan\n",
      "    use_flag                 (station, date_time) float64 1.0 1.0 ... nan nan\n",
      "    filename                 (station) object 'acajutla-082c-slv-uhslc' ... '...\n",
      "    site_name                (station) object 'Acajutla' ... 'Abrams_River'\n",
      "    site_code                (station) object '082C' 'HD26' '8761494' '380'\n",
      "    ...                       ...\n",
      "    datum_information        (station) object 'Unspecified' ... 'Chart Datum ...\n",
      "    instrument               (station) object 'Unspecified' ... 'Unspecified'\n",
      "    precision                (station) object 'Unspecified' ... 'Unspecified'\n",
      "    null_value               (station) float64 -100.0 -100.0 -100.0 -100.0\n",
      "    gauge_type               (station) object 'Coastal' 'Coastal' ... 'Coastal'\n",
      "    overall_record_quality   (station) object 'No obvious issues' ... 'No obv...\n"
     ]
    }
   ],
   "source": [
    "filenames = [\n",
    "    \"abrams_river-380-can-meds\",\n",
    "    \"acajutla-082c-slv-uhslc\", \n",
    "    \"yoshioka-hd26-jpn-jodc_jcg\", \n",
    "    \"west_point_a_la_hache-8761494-usa-noaa\",\n",
    "]\n",
    "xr_dataset = g3.files_to_xarray(filenames)\n",
    "print(xr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the N closest records to a lat/lon location\n",
    "Load data from records close to a particular location using the function `load_N_closest` as follows. Provide a lat/lon location and the number of desired records. The function returns a `xarray.Dataset` object containing data, flags, and metadata.  \n",
    "\n",
    "Note the `UserWarning` that occurs when duplicate timestamps are encountered. The function `file_to_pandas` used to read each individual file keeps only the first of any duplicate timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/Dropbox (Personal)/Research/Data/TideGaugeSets/GESLAv3/GeslaDataset/gesla.py:65: UserWarning: Duplicate timestamps in file yarmouth-365-can-meds were removed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yarmouth' 'Lower_Wedgeport' 'Pinkney_Point' 'Abbotts_Harbour'\n",
      " 'Clarks_Harbour' 'Woods_Harbour' 'Tusket' 'Abrams_River' 'Flat_Island'\n",
      " 'Wedgeport']\n"
     ]
    }
   ],
   "source": [
    "data = g3.load_N_closest(lat=43.83, lon=-65.95, N=10)\n",
    "print(data.site_name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the records in a lat/lon range\n",
    "Load data from records in a rectangular lat/lon range using the function `load_lat_lon_range` as follows. Provide lat/lon extents of the range. The function returns a `xarray.Dataset` object containing data, flags, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honolulu_Hawaii' 'Hilo_Hawaii' 'Midway' 'Johnston' 'Kahului'\n",
      " 'Nawiliwili' 'Mokuoloe' 'French_Frigate' 'Kawaihae' 'French_Frigate'\n",
      " 'Barbers_Point_HI' 'Honolulu_Kewalo' 'Port_Allen' 'Kaumalapau_HI'\n",
      " 'Honolulu_Hawaii' 'Honolulu_Pier_45' 'Honolulu' 'Hilo' 'Nawiliwili'\n",
      " 'Sand_Island' 'Kahului' 'Mokuoloe' 'Kawaihae' 'Johnston_Atoll'\n",
      " 'Port_Allen' 'Kaumalapau_Harbor' 'Kaunakakai_Harbor' 'Laiemaloo'\n",
      " 'Fort_Kamehameha' 'Ford_Island']\n"
     ]
    }
   ],
   "source": [
    "south_lat = 15\n",
    "north_lat = 30\n",
    "west_lon = -180\n",
    "east_lon = -140\n",
    "\n",
    "data = g3.load_lat_lon_range(\n",
    "    south_lat=south_lat,\n",
    "    north_lat=north_lat,\n",
    "    west_lon=west_lon,\n",
    "    east_lon=east_lon,\n",
    ")\n",
    "print(data.site_name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b2458d0610a23fbd5c707a25149dc9218000ef165f906d82c15727d18cbe22b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
